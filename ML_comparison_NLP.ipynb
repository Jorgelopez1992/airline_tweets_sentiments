{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV,LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB,MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import metrics\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import random\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3071: DtypeWarning: Columns (7,9) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "/opt/anaconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3071: DtypeWarning: Columns (12) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"labeled_data2.csv\") # Training data (labeled)\n",
    "new_data = pd.read_csv(\"api_data2.csv\") # API data (unlabeled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data =  data.sample(frac=1)        #shuffling data \n",
    "y    =  data['airline_sentiment']\n",
    "X    =  data\n",
    "Xnew = new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping columns that will not be used to classify \n",
    "X = X.drop(columns=['Unnamed: 0', 'tweet_id','airline_sentiment','airline_sentiment_confidence','negativereason','negativereason_confidence','airline_sentiment_gold','negativereason_gold'])\n",
    "X = X.drop(columns=['text','hashtags','user_timezone','tweet_coord','hashtags','full_text_processed','sents','words','clean_words'])\n",
    "X = X.drop(columns=['user_location','tweet_location','tweet_created','user_acc_date','lang','name','airline','user_verified'])\n",
    "\n",
    "Xnew = Xnew.drop(columns=['Unnamed: 0', 'tweet_id','airline_sentiment','airline_sentiment_confidence','negativereason','negativereason_confidence','airline_sentiment_gold','negativereason_gold'])\n",
    "Xnew = Xnew.drop(columns=['text','hashtags','user_timezone','tweet_coord','hashtags','full_text_processed','sents','words','clean_words'])\n",
    "Xnew = Xnew.drop(columns=['user_location','tweet_location','tweet_created','user_acc_date','lang','name','airline','user_verified'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split into train/test\n",
    "index  =  round(.7*14640)\n",
    "Xtrain =  X[1:index]\n",
    "Xtest  =  X[index:14640]\n",
    "ytrain =  y[1:index]\n",
    "ytest  =  y[index:14640]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['retweet_count', 'upper_count', 'caps_ratio', 'num_expletives',\n",
       "       'pun_ratio', '000', '10', '100', '10k', '11',\n",
       "       ...\n",
       "       '#wearetexans', '#welcome', '#winginit', '#wishfulwednesdays',\n",
       "       '#workersfirst', '#worldkindnessday', '#wtf', '#wtmldn', '#yellowfever',\n",
       "       '#youarewhywefly'],\n",
       "      dtype='object', length=1255)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtrain.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithim Comparisons \n",
    "Comparison of different models and how they differed in accuracy as well as time in a natural language processing setting. The classification models compared were Naive Bayes, Random Forest, Logistic Regression, and Elastic Net Logistic Regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multinomial naive bayes\n",
    "\n",
    "t0= time.time()\n",
    "mnb             =  MultinomialNB()\n",
    "\n",
    "mnb.fit(Xtrain,ytrain)\n",
    "\n",
    "t1 = time.time() - t0\n",
    "print(\"Time elapsed: \", t1)\n",
    "\n",
    "mnb.score(Xtrain,ytrain)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RANDOM FOREST \n",
    "t0= time.time()\n",
    "rf            =  RandomForestClassifier(n_estimators=500, random_state=0)\n",
    "rf.fit(Xtrain,ytrain)\n",
    "\n",
    "t1 = time.time() - t0\n",
    "print(\"Time elapsed: \", t1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression \n",
    "t0= time.time()\n",
    "log_model = LogisticRegression(multi_class='multinomial')\n",
    "log_model.fit(Xtrain,ytrain)\n",
    "log_model.score(Xtest,ytest)\n",
    "t1 = time.time() - t0\n",
    "print(\"Time elapsed: \", t1)\n",
    "# So far Logistic model has performed the best on the dataset,\n",
    "# but the model can be improved upon by using regularization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elastic Net logistic Regression\n",
    "t0= time.time()\n",
    "elas_log     =  LogisticRegressionCV(penalty='elasticnet',cv=10,l1_ratios=[0.2,0.5,0.7],max_iter=5000,solver='saga')\n",
    "elas_log.fit(Xtrain,ytrain)\n",
    "elas_log.score(Xtest,ytest)\n",
    "t1 = time.time() - t0\n",
    "print(\"Time elapsed: \", t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions=elas_log.predict(Xnew)\n",
    "new_data['predicted_sentiment']=predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new_data.to_csv(\"predictions_api_full.csv\",sep=\",\",encoding='utf-8') \n",
    "#predicted labels for api data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results for each model on the test set in terms of accuracy are surprisingly very close to each other, although it must be noted that they differred greatly in time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Naive Bayes Train Accuracy:\",mnb.score(Xtrain,ytrain))\n",
    "print(\"Random Forest Train Accuracy:\",rf.score(Xtrain,ytrain))\n",
    "print(\"Logistic Regression Train Accuracy:\",log_model.score(Xtrain,ytrain))\n",
    "print(\"Elastic Net Train Accuracy:\",elas_log.score(Xtrain,ytrain))\n",
    "\n",
    "print(\"Naive Bayes Test Accuracy:\",mnb.score(Xtest,ytest))\n",
    "print(\"Random Forest Test Accuracy:\",rf.score(Xtest,ytest))\n",
    "print(\"Logistic Regression Test Accuracy:\",log_model.score(Xtest,ytest))\n",
    "print(\"Elastic Net Test Accuracy:\",elas_log.score(Xtest,ytest))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Elastic Net Coefficients\n",
    "Due to sparsity of bag of words matrix, regularization will help improve the logistic regression model as well as perform some variable selection that can give insight into what words and features were most strongly associated with positive & negative sentiments. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_y=[]\n",
    "for label in ytrain:\n",
    "    if label=='negative':\n",
    "        neg_y.append(1)\n",
    "    else:\n",
    "        neg_y.append(0)\n",
    "        \n",
    "neg_log_model = LogisticRegressionCV(penalty='elasticnet',cv=10,l1_ratios=[0.2,0.5,0.7],max_iter=5000,solver='saga')\n",
    "neg_log_model.fit(Xtrain,neg_y)\n",
    "coefs = neg_log_model.coef_\n",
    "\n",
    "#creating matrix of values \n",
    "coefs = log_model.coef_\n",
    "words_list=list(Xtrain.columns)\n",
    "neg_matrix=pd.DataFrame()\n",
    "neg_matrix['variable']=words_list\n",
    "neg_matrix['coef_value']=coefs[0]\n",
    "neg_matrix=neg_matrix.sort_values(by='coef_value',ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_y=[]\n",
    "for label in ytrain:\n",
    "    if label=='positive':\n",
    "        pos_y.append(1)\n",
    "    else:\n",
    "        pos_y.append(0)\n",
    "        \n",
    "pos_log_model = LogisticRegressionCV(penalty='elasticnet',cv=10,l1_ratios=[0.2,0.5,0.7],max_iter=5000,solver='saga')\n",
    "pos_log_model.fit(Xtrain,pos_y)\n",
    "\n",
    "#creating matrix of values \n",
    "coefs        =  pos_log_model.coef_\n",
    "words_list   =  list(Xtrain.columns)\n",
    "pos_matrix   =  pd.DataFrame()\n",
    "\n",
    "pos_matrix['variable']    =  words_list\n",
    "pos_matrix['coef_value']  =  coefs[0]\n",
    "\n",
    "pos_matrix   =  pos_matrix.sort_values(by='coef_value',ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_matrix.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_matrix.head(15)\n",
    "#pos_matrix.to_csv(\"pos_coefs.csv\",sep=\",\",encoding='utf-8')\n",
    "#neg_matrix.to_csv(\"neg_coefs.csv\",sep=\",\",encoding='utf-8')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
