{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tweepy\n",
    "from tweepy import API \n",
    "from tweepy import OAuthHandler\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#empty lists to store data\n",
    "\n",
    "#\"tweet_coord\",\n",
    "#\"tweet_location\",\"user_timezone\"  \n",
    "columns_names=[]\n",
    "created_at=[] #\"tweet_created\"\n",
    "id=[] # \"tweet_id\" \n",
    "full_text=[] #\"text\"\n",
    "entities_hashtag=[] \n",
    "user_name=[] #\"name\"\n",
    "user_screen_name=[] #name\n",
    "user_location=[] #\"tweet_location\"\n",
    "coordinates=[] #\"tweet_coord\"\n",
    "retweet_count=[]#\"retweet_count\"\n",
    "lang=[] \n",
    "user_acc_date=[]\n",
    "user_verified=[]\n",
    "full_retweet=[]\n",
    "\n",
    "#these are the phrases we will be searching for with the twitter API \n",
    "air_search_parameter=['@united','@AmericanAir','@Delta','@SouthwestAir','@FlyFrontier',  \n",
    "                      '@SpiritAirlines','@SunCountryAir','@AlaskaAir','@CapeAir',\n",
    "                      '@HawaiianAir','@VirginAmerica','@JetBlue','@USAirways']\n",
    "\n",
    "airline_list=['United','American','Delta','Southwest','Fly Frontier',\n",
    "              'Spirit Airlines','Sun Country Air','Alaska Air','Cape Air',\n",
    "              'Haiwaiin Air','Virgin America','Jet Blue','US Airways']\n",
    "\n",
    "airlines=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setup access to API, please note that you would need to enter your own personal keys/tokens \n",
    "# API keys have to be requested from twitter on your account\n",
    "twitter_keys = {\n",
    "        'consumer_key':        '######################',\n",
    "        'consumer_secret':     '######################',\n",
    "        'access_token_key':    '######################',\n",
    "        'access_token_secret': '#######################'\n",
    "    }\n",
    "\n",
    "auth = tweepy.OAuthHandler(twitter_keys['consumer_key'], twitter_keys['consumer_secret'])\n",
    "auth.set_access_token(twitter_keys['access_token_key'], twitter_keys['access_token_secret'])\n",
    "\n",
    "# only ~15,0000 tweets can be gathered every 15 minutes\n",
    "# We set wait_on_rate_limit to True in order to avoid timing out. \n",
    "api = tweepy.API(auth,wait_on_rate_limit=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ticker=0  # allows us to keep track of which airline the tweet is directed at\n",
    "i=0       # keeps track of tweets \n",
    "\n",
    "for q_search in air_search_parameter:     # loop that goes through airline \n",
    "    airline=airline_list[ticker]          # variable to keep track of airline \n",
    "    \n",
    "    # each \"page\" is a collection of ~100 or so tweets gathered at once from the api \n",
    "    # q=q_search parameter tells the api what phrase to search for, \n",
    "    # an example would be '@united' which would return all tweets containing the string '@united'\n",
    "    # tweet_mode=extended allows us to extract text even if it is a retweet. \n",
    "    # Please note that you can only search as far back as a week\n",
    "    for page in tweepy.Cursor(api.search, q=q_search, count=100,since=\"2020-11-25\",              \n",
    "                               until=\"2020-12-02\",lang='en', tweet_mode='extended').pages(1000):\n",
    "        \n",
    "        for k in range(0,len(page)):  # loop through every tweet in the page\n",
    "            \n",
    "            #each tweet comes in a json format, and we extract the relevant variables from it \n",
    "            try: \n",
    "                status=page[k]._json   \n",
    "                created_at.append(status['created_at']) #\"tweet_created\"\n",
    "                id.append(status['id']) # \"tweet_id\" \n",
    "                full_text.append(status['full_text']) #\"text\"\n",
    "                t_entities_hashtag=status['entities']['hashtags'] # possibly important\n",
    "                hashtags=[] #possibly important\n",
    "                for k in range(0,len(t_entities_hashtag)):\n",
    "                    hashtags.append(t_entities_hashtag[k]['text'])\n",
    "                entities_hashtag.append(hashtags)\n",
    "                user_name.append(status['user']['name']) #\"name\"\n",
    "                user_screen_name.append(status['user']['screen_name']) #\"user_name\"\n",
    "                user_location.append(status['user']['location'])#\"tweet_location\"\n",
    "                user_acc_date.append(status['user']['created_at']) \n",
    "                user_verified.append(status['user']['verified'])\n",
    "                coordinates.append(status['coordinates']) #\"tweet_coord\"\n",
    "                airlines.append(airline)\n",
    "                retweet_count.append(status['retweet_count']) #\"retweet_count\"\n",
    "                lang.append(status['lang'])\n",
    "                i=i+1\n",
    "            except:\n",
    "                continue\n",
    "                \n",
    "        print(str(i)+' tweets collected so far') \n",
    "    print(q_search)\n",
    "    print(airline)\n",
    "    print('FINISHED')\n",
    "    ticker=ticker+1                             #move on to the next airline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creates dataframe from columns using pandas\n",
    "\n",
    "columns = {'tweet_created':created_at,  #\"tweet_created\"\n",
    "        'tweet_id':id,  # \"tweet_id\" \n",
    "        'text':full_text, #\"text\"\n",
    "        'airline': airlines, #airline\n",
    "        'hashtags':entities_hashtag,\n",
    "        'name':user_name, #\"name\"\n",
    "        'user_screen_name':user_screen_name, #\"name\"???\n",
    "        'user_location':user_location, #\"tweet_location\"\n",
    "        'user_acc_date':user_acc_date,\n",
    "        'user_verified':user_verified,\n",
    "        'tweet_coord':coordinates, #\"tweet_coord\"\n",
    "        'retweet_count':retweet_count, #\"retweet_count\"\n",
    "        'lang':lang}\n",
    "\n",
    "df = pd.DataFrame(columns)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"airline_tweets_nov_25-Dec_02.csv\",sep=\",\",encoding='utf-8')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
